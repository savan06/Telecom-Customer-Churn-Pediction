#import necessary libraies
import pandas as pd
import numpy as np 
import pickle
import matplotlib.pyplot as plt
import IPython
print(IPython.sys_info())
# %matplotlib inline

import seaborn as sns 
import sklearn 
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
from sklearn.linear_model import LogisticRegression 
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.model_selection import RandomizedSearchCV
import imblearn
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score

from google.colab import drive
drive.mount('/content/drive')

with open('/content/drive/My Drive/Colab Notebooks/Intelligent Customer Retention/data/Dataset.csv','r') as dataset:
  data = pd.read_csv(dataset)

data.info()

#checking for null values
data.TotalCharges = pd.to_numeric(data.TotalCharges, errors='coerce')
data.isnull().any()

data["TotalCharges"].fillna(data ["TotalCharges"].median(), inplace=True)
data.isnull().sum()

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
data["gender"]=le.fit_transform(data["gender"])
data["Partner"]=le.fit_transform(data["Partner"])
data["Dependents"]=le.fit_transform(data["Dependents"])
data["PhoneService"]=le.fit_transform(data["PhoneService"])
data["MultipleLines"]=le.fit_transform(data["MultipleLines"])
data["InternetService"]=le.fit_transform(data["InternetService"])
data["OnlineSecurity"]=le.fit_transform(data["OnlineSecurity"])
data["OnlineBackup"]=le.fit_transform(data["OnlineBackup"])
data["DeviceProtection"]=le.fit_transform(data["DeviceProtection"])
data["TechSupport"]=le.fit_transform(data["TechSupport"])
data["StreamingTV"]=le.fit_transform(data["StreamingTV"])
data["SteamingMovies"]=le.fit_transform(data["StreamingMovies"])
data["Contract"]=le.fit_transform(data["Contract"])
data["PaperlessBilling"]=le.fit_transform(data["PaperlessBilling"])
data["PaymentMethod"]=le.fit_transform(data["PaymentMethod"])
data["Churn"]=le.fit_transform(data["Churn"])

data.head()

x= data.iloc[:,0:19].values
y= data.iloc[:,19:20].values

print(x)
print(y)

from sklearn.preprocessing import OneHotEncoder
one=OneHotEncoder()
a=one.fit_transform(x[:,6:7]).toarray()
b=one.fit_transform(x[:,7:8]).toarray()
c=one.fit_transform(x[:,8:9]).toarray()
d=one.fit_transform(x[:,9:10]).toarray()
e=one.fit_transform(x[:,10:11]).toarray()
f=one.fit_transform(x[:,11:12]).toarray()
g=one.fit_transform(x[:,12:13]).toarray()
h=one.fit_transform(x[:,13:14]).toarray()
i=one.fit_transform(x[:,14:15]).toarray()
j=one.fit_transform(x[:,16:17]).toarray()
x=np.delete(x,[6,7,8,9,10,11,12,13,14,16],axis=1)
x=np.concatenate((a,b,c,d,e,f,g,h,i,j,x),axis=1)

pip install imblearn

from imblearn.over_sampling import SMOTE

from imblearn.over_sampling import SMOTE

smt = SMOTE()
x_resample, y_resample = smt.fit_resample(x, y)

#x_resample

#y_resample

#x.shape,x_resample.shape

#y.shape,y_resample.shape

data.describe()

plt.figure(figsize=(12,5))
plt.subplot(1,2,1)
sns.distplot(data["tenure"])
plt.subplot(1,2,2)
sns.distplot(data["MonthlyCharges"])

plt.figure(figsize=(12,5))
plt.subplot(1,2,1)
sns.countplot(data["gender"])
plt.subplot(1,2,2)
sns.countplot(data["Dependents"])

sns.barplot(x="Churn",y="MonthlyCharges",data=data)

sns.heatmap(data.corr(), annot=True)

sns.pairplot(data=data, markers=["^","v"], palette="inferno")

from sklearn.model_selection import train_test_split
#x_train,x_test,y_train,y_test=train_test_split(x_resample,y_resample,test_size=0.2,random_state=0)

from sklearn.preprocessing import StandardScaler
#sc = StandardScaler()
#x_train = sc.fit_transform(x_train)
#x_test = sc.fit_transform(x_test)

#x_train.shape

#x_train.shape

#printing the train accuacy and test accuracy respectively
#logreg(x_train,x_test,y_train,y_test)

#impoting and building the Decision tree model
def decisionTree(x_train,x_test,y_train,y_test):
#dtc = DecisionTreeClassifier(criterion="entropy",random_state=0)
#dtc.fit(x_train,y_train)
#y_dt_tr=dtc.predict(x_train)
#print(accuracy_score(y_dt_tr,y_train))
#ypred_dt=dtc.predict(x_test)
 # print(accuracy_score(ypred_dt,y_train))
 # print("***Decision Tree***")
  #print("Confution_Matrix")
  #print(confution_matrix(y_test,y_pred_dt))
  print("Classification Report")
  p#rint(classification_report(y_test,y_pred_dt))

#printing the train accuracy and test accuracy respectively
#decisionTree(x_train,x_test,y_train,y_test)

#importing and building the random forest model
#def andomForest(x_train,x_test,y_train,y_test):
#rf = RandomForestClassifier(criterion="entropy",n_estimators=10,random_state=0)
#rf.fit(x_train,y_train)
#y_rf_tr=rf.predict(x_train)
#print(accuracy_score(ypred_rf,y_train))
 # ypred_rf=rf.predict(x_test)
 #3 print(accuracy_score(ypred_rf,y_train))
  #print("***Random Forest***")
  #print("Confution_Matrix")
  #print(confution_matrix(y_test,y_pred_rf))
  #print("Classification Report")

#importing and building the KNN model
#def KNN(x_train,x_test,y_tain,y_test):
 # knn-KNeighborsClassifier()
  #knn.fit(x_train,y_train)
  #y_knn_tr=knn.predict(x_train)
  #print(accuracy_score(y_knn_tr,y_train))
  #ypred_knn=knn.predict(x_test)
  #print(accuracy_score(ypred_knn,y_train))
  #print("***KNN***")
  #print("Confution_Matrix")
  #print(confution_matrix(y_test,y_pred_knn))
  #print("Classification Report")
  #print(classification_report(y_test,y_pred_knn))

#pinting the tain accuracy and test acccuacy respectively
#KNN(x_train,x_test,y_train,y_test)

#printing the train accuracy and test accuracy respectively
#svm(x_train,x_test,y_train,y_test)

# Impoting the Keas libraries and package
import keras
from keras.models import Sequential
from keras.layers import Dense

#classifier=sequential

#classifier.add(Dense(units=30,activation='relu',input_dim=40))

#classsifier.add(Dense(units=30,activation='relu'))

#classsifier.add(Dense(units=1,activation='sigmoid'))

#classifier.compile(optimizer='adam',loss='binary'_crossentropy',metrics=['accuracy'])

#model_history=classifier.fit(x_train,y_train,batch_size=10,validation_split=0.33,epochs=200)

#ann_pred=classifier.predict(x_test)
#ann_pred=(ann_pred>0.5)
#ann_pred

#print(accuracy_score(ann_pred,y_test))
#print("***ANN Model***")
#print("Confution_Matrix")
#print(confsion_matrix(y_test,ann_pred))
#print("Classification Report")
#print(classification_report)(y_test,ann_pred))

#lr=LogisticRegression(random_state=0)
#lr.fit(x_train,y_train)
#print("Predicting on random input")
#lr_pred_own=lr.predict(sc.transform([[0,0,1,1,0,0,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,1,0,0,1,1,0,0,456,1,0,3245,4567]]))
#print("output is:",lr_pred_own)

#dtc=DecisionTreeClassifier(criterion="entropy",random_state=0)
#dtc.fit(x_train,y_train)
#print("Prediciting on random input")
#dtc_pred_own=dtc.predict(sc.transform([[0,0,1,1,0,0,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,1,0,0,1,1,0,0,456,1,0,3245,4567]]))
#print("output is:",dtc_pred_own)

#rf=RandomForestClassifier(criterion="entropy",n_estimaters=10,random_state=0)
#rf.fit(x_train,y_train)
#print("Prediciting on random input")
#rf_pred_own=rf.predict(sc.transform([[0,0,1,1,0,0,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,1,0,0,1,1,0,0,456,1,0,3245,4567]]))
#print("output is:",rf_pred_own)

#svc=SVC(kernel="linear")
#svc.fit(x_train,y_train)
#print("Prediciting on random input")
#svm_pred_own=svc.predict(sc.transform([[0,0,1,1,0,0,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,1,0,0,1,1,0,0,456,1,0,3245,4567]]))
#print("output is:",svm_pred_own)

#knn=KNeighborsClassifier()
#knn.fit(x_train,y_train)
#print("Prediciting on random input")
#knn_pred_own=knn.predict(sc.transform([[0,0,1,1,0,0,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,1,0,0,1,1,0,0,456,1,0,3245,4567]]))
#print("output is:",knn_pred_own)

#print("Prediciting on random input")
#ann_pred_own=classifier.predict(sc.transform([[0,0,1,1,0,0,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,1,0,0,1,1,0,0,456,1,0,3245,4567]]))
#print(ann_pred_own)
#ann_pred_own=(ann_pred_own>.5)
#print("output is:",ann_pred_own)

#def compareModel(x_train,x_test,y_train,y_test):
 # logreg(x_train,x_test,y_train,y_test)
  #print('-'*100)
  #decisionTree(x_train,x_test,y_train,y_test)
  #print('-'*100)
  #RandomForest(x_train,x_test,y_train,y_test)
  #print('-'*100)
  #svm(x_train,x_test,y_train,y_test)
  #print('-'*100)
  #KNN(x_train,x_test,y_train,y_test)
  #print('-'*100)

#compareModel(x_train,x_test,y_train,y_test)

#print(accuacy_score(ann_pred,y_test))
#print("***ANN Model***")
#print("Confution_Matrix")
#print(confution_matrix(y_test,ann_pred))
#print("Classification Report")
#print(classification_report(y_test,ann_pred))

#y_rf=model.predict(x_train)
#print(accuracy_score(y_rf,y_train))
#ypred_rfcv=model.predict(x_test)
#print(accuracy_score(ypred_rfcv,y_test))
#print("***Random Forset after Hyperparameter tuning***")
#print("Confusion_Matrix")
#print(confusion_matrix(y_test,ypred_rfcv))
#print("Classification Report")
#print(classification_report(y_test,ypred_rfcv))
#print("Prediction on random input")
#rfcv_pred_own = model.predict(sc.transform([[0,0,1,1,0,0,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,0,1,0,1,0,0,1,1,0,0,456,1,0,3245,4567]]))
#print("output is: ",rfcv_pred_own)

#classsifier.save("telcom_churn.h5")